(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{394:function(a,v,_){"use strict";_.r(v);var t=_(46),r=Object(t.a)({},(function(){var a=this,v=a.$createElement,_=a._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[_("h1",{attrs:{id:"异常检测"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#异常检测"}},[a._v("#")]),a._v(" 异常检测")]),a._v(" "),_("h2",{attrs:{id:"介绍"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#介绍"}},[a._v("#")]),a._v(" 介绍")]),a._v(" "),_("h3",{attrs:{id:"异常检测定义"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#异常检测定义"}},[a._v("#")]),a._v(" 异常检测定义")]),a._v(" "),_("p",[a._v("异常检测（Anomaly detection）也称离群点检测，是目前时序数据分析最成熟的应用之一，是从正常的时间序列中识别不正常的事件或行为的过程。")]),a._v(" "),_("h3",{attrs:{id:"异常类型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#异常类型"}},[a._v("#")]),a._v(" 异常类型")]),a._v(" "),_("p",[a._v("点异常(point)、上下文异常(contextual)、集合异常(collective)")]),a._v(" "),_("h3",{attrs:{id:"异常检测方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#异常检测方法"}},[a._v("#")]),a._v(" 异常检测方法")]),a._v(" "),_("ol",[_("li",[a._v("直接检测：针对点异常，直接定位离群点，也称离群值检测。")]),a._v(" "),_("li",[a._v("间接检测：上下文或集合异常先转化成点异常，然后再求解。")]),a._v(" "),_("li",[a._v("时间跨度检测: ARIMA，回归模型，LSTM等，核心思想就是模型学习一段历史数据，然后预测, 通过比对真实值与预测值的偏差来判断是否为异常。")]),a._v(" "),_("li",[a._v("序列跨度检测：许多传感器应用程序产生的时间序列通常彼此紧密相关。例如，在一个传感器上的鸟叫通常也会被附近的传感器记录下来。在这种情况下，经常可以使用一个序列来预测另一个序列。与此类预期预测的偏差可以报告为异常值，如隐式马尔科夫链HMM等。")])]),a._v(" "),_("h2",{attrs:{id:"时间序列的特征工程"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#时间序列的特征工程"}},[a._v("#")]),a._v(" 时间序列的特征工程")]),a._v(" "),_("h3",{attrs:{id:"非数值型变量处理方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#非数值型变量处理方法"}},[a._v("#")]),a._v(" 非数值型变量处理方法")]),a._v(" "),_("h4",{attrs:{id:"分布概率转化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布概率转化"}},[a._v("#")]),a._v(" 分布概率转化")]),a._v(" "),_("p",[a._v("变量不再默认服从特定分布（如高斯），而需要单独根据具体数据集定义概率分布（按比例），并按乘积方式与数 值变量组合以创建单个多元分布。")]),a._v(" "),_("h4",{attrs:{id:"线性转化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#线性转化"}},[a._v("#")]),a._v(" 线性转化")]),a._v(" "),_("ul",[_("li",[_("p",[a._v("One-hot码二进制转换，一个值对应一个种类，但容易维度爆炸，且无法体现不同类别的不同权重。可以通过将每列除以其标准偏差（deviation）来进行归一化。")])]),a._v(" "),_("li",[_("p",[a._v("潜在语义分析(Latent Semantic Analysis)")])])]),a._v(" "),_("h4",{attrs:{id:"基于相似度量的转化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于相似度量的转化"}},[a._v("#")]),a._v(" 基于相似度量的转化")]),a._v(" "),_("ul",[_("li",[_("p",[a._v("基于数据的统计邻域计算相似度，比如文本变量中“红色”和“橙色”比“红色”和“蓝色”更相近，但要求人为区分属性值之间的语义关系。")])]),a._v(" "),_("li",[_("p",[a._v("邻域相似度计算")])])]),a._v(" "),_("h3",{attrs:{id:"特征工程的构造思路"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#特征工程的构造思路"}},[a._v("#")]),a._v(" 特征工程的构造思路")]),a._v(" "),_("ol",[_("li",[_("p",[a._v("统计特征")]),a._v(" "),_("ul",[_("li",[a._v("max、min、interval")]),a._v(" "),_("li",[a._v("avg、median")]),a._v(" "),_("li",[a._v("variance、偏度、峰度")]),a._v(" "),_("li",[a._v("同比、环比")]),a._v(" "),_("li",[a._v("重复值")])])]),a._v(" "),_("li",[_("p",[a._v("拟合特征")]),a._v(" "),_("ul",[_("li",[a._v("移动平均算法")]),a._v(" "),_("li",[a._v("带权重的移动平均算法")]),a._v(" "),_("li",[a._v("1/2/3次指数移动平均算法")]),a._v(" "),_("li",[a._v("SVD算法")]),a._v(" "),_("li",[a._v("线性拟合")]),a._v(" "),_("li",[a._v("自回归:AR/MA/ARMA/ARIMA/卡尔曼滤波器")])])]),a._v(" "),_("li",[_("p",[a._v("时域特征")]),a._v(" "),_("ul",[_("li",[a._v("自相关，偏相关系数")]),a._v(" "),_("li",[a._v("差分")]),a._v(" "),_("li",[a._v("赫斯特指数")]),a._v(" "),_("li",[a._v("趋势、周期")]),a._v(" "),_("li",[a._v("噪声")])])]),a._v(" "),_("li",[_("p",[a._v("频域特征")]),a._v(" "),_("ul",[_("li",[a._v("小波分析特征（大象流/老鼠流）：小波变换系数、变换波峰数、变换均值")]),a._v(" "),_("li",[a._v("傅里叶变换偏度、峰度、方差、系数等")])])])]),a._v(" "),_("h3",{attrs:{id:"特征选择的方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#特征选择的方法"}},[a._v("#")]),a._v(" 特征选择的方法")]),a._v(" "),_("h4",{attrs:{id:"相关度-筛除无关特征"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#相关度-筛除无关特征"}},[a._v("#")]),a._v(" 相关度(筛除无关特征)")]),a._v(" "),_("h4",{attrs:{id:"pca主成分分析-筛除多重共线性特征"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#pca主成分分析-筛除多重共线性特征"}},[a._v("#")]),a._v(" PCA主成分分析(筛除多重共线性特征)")]),a._v(" "),_("p",[a._v("PCA(Principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据降维算法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1，2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。")]),a._v(" "),_("p",[a._v("算法步骤：")]),a._v(" "),_("div",{staticClass:"language-none extra-class"},[_("pre",{pre:!0,attrs:{class:"language-text"}},[_("code",[a._v("1. 去平均值(即去中心化)，即每一位特征减去各自的平均值。\n\n2. 计算协方差矩阵。\n\n3. 用特征值分解方法求协方差矩阵的特征值与特征向量。\n\n4. 对特征值从大到小排序，选择其中最大的k个。然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P。\n\n5. 将数据转换到k个特征向量构建的新空间中，即Y=PX。\n")])])]),_("h4",{attrs:{id:"树模型输出特征重要性排序-有监督场景"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#树模型输出特征重要性排序-有监督场景"}},[a._v("#")]),a._v(" 树模型输出特征重要性排序(有监督场景)")]),a._v(" "),_("h2",{attrs:{id:"时序异常检测算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#时序异常检测算法"}},[a._v("#")]),a._v(" 时序异常检测算法")]),a._v(" "),_("p",[a._v("基本上，一个异常检测算法要么在每个时间点上标记异常/非异常；要么预测某个时间点的信号，并测试这个时间点的值是否与预测值有足够的差异，从而将其视为异常。\n"),_("img",{attrs:{src:"/blog/img/anomaly_detection.png",alt:"异常检测"}})]),a._v(" "),_("h3",{attrs:{id:"stl分解"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#stl分解"}},[a._v("#")]),a._v(" STL分解")]),a._v(" "),_("p",[a._v("使用 STL 分解法将时间序列数据表示成三个要素：季节性、趋势、残差。通过分析残差的背离程度，引入一定的阈值，我们可以使用绝对中位差来作为阈值。")]),a._v(" "),_("h3",{attrs:{id:"分类与回归树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分类与回归树"}},[a._v("#")]),a._v(" 分类与回归树")]),a._v(" "),_("p",[a._v("分类和回归树算法有两种使用方式：一种是准备好已标记过异常点的数据集，进行监督型的机器学习；另一种则是让 CART 算法自动寻找数据集中的模式，预测异常点的置信区间。")]),a._v(" "),_("h3",{attrs:{id:"arima"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#arima"}},[a._v("#")]),a._v(" ARIMA")]),a._v(" "),_("p",[a._v("ARIMA模型，差分整合移动平均自回归模型，又称整合移动平均自回归模型，是时间序列预测分析方法之一。ARIMA(p，d，q)中，AR是“自回归”，p为自回归项数；MA为“滑动平均”，q为滑动平均项数，d为使之成为平稳序列所做的差分次数。“差分”一词虽未出现在ARIMA的英文名称中，却是关键步骤。它基于一个方法，从过去的几个点产生下一个点的预测加上一些随机变量，通常是白噪声。它对预测范围的明显影响是:信号变得更平滑。")]),a._v(" "),_("h3",{attrs:{id:"指数平滑法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#指数平滑法"}},[a._v("#")]),a._v(" 指数平滑法")]),a._v(" "),_("p",[a._v("指数平滑法实际上是一种特殊的加权移动平均法。其特点是: 第一，指数平滑法进一步加强了观察期近期观察值对预测值的作用，对不同时间的观察值所赋予的权数不等，从而加大了近期观察值的权数，使预测值能够迅速反映市场实际的变化。权数之间按等比级数减少，此级数之首项为平滑常数a,公比为(1- a)。第二，指数平滑法对于观察值所赋予的权数有伸缩性，可以取不同的a 值以改变权数的变化速率。如a取小值，则权数变化较迅速，观察值的新近变化趋势较能迅速反映于指数移动平均值中。因此，运用指数平滑法，可以选择不同的a 值来调节时间序列观察值的均匀程度(即趋势变化的平稳程度)。")]),a._v(" "),_("h3",{attrs:{id:"神经网络"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[a._v("#")]),a._v(" 神经网络")]),a._v(" "),_("p",[a._v("和CART一样，有两种方法可以应用神经网络:监督学习和非监督学习。当我们处理时间序列时，最合适的神经网络类型是LSTM。这种类型的递归神经网络，如果正确地构建，将允许您在您的时间序列中建模最复杂的依赖关系，以及高级的季节性依赖关系。如果有多个时间序列相互耦合，这种方法也非常有用。")]),a._v(" "),_("h3",{attrs:{id:"基于统计的算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于统计的算法"}},[a._v("#")]),a._v(" 基于统计的算法")]),a._v(" "),_("ol",[_("li",[_("p",[a._v("针对单变量数据")]),a._v(" "),_("ul",[_("li",[a._v("集中不等式")]),a._v(" "),_("li",[a._v("马尔可夫不等式")]),a._v(" "),_("li",[a._v("切比雪夫不等式")]),a._v(" "),_("li",[a._v("统计置信检验")]),a._v(" "),_("li",[a._v("3-sigma")]),a._v(" "),_("li",[a._v("t检验、f检验、卡方检验")]),a._v(" "),_("li",[a._v("ARIMA类")]),a._v(" "),_("li",[a._v("Grubbs测试：Grubbs测试是一种从样本中找出outlier的方法，所谓   outlier，是指样本中偏离平均值过远的数据，他们有可能是极端情况下的正常数据，也有可能是测量过程中的错误数据。使用Grubbs测试需要总体是正态分布的。\n算法流程：\n"),_("ul",[_("li",[a._v("样本从小到大排序")]),a._v(" "),_("li",[a._v("求样本的mean和std.dev")]),a._v(" "),_("li",[a._v("计算min/max与mean的差距，更大的那个为可疑值")]),a._v(" "),_("li",[a._v("求可疑值的z-score (standard score)，如果大于Grubbs临界值，那么就是outlier")]),a._v(" "),_("li",[a._v("Grubbs临界值可以查表得到，它由两个值决定：检出水平α（越严格越小），样本数量n。排除outlier，对剩余序列循环做 1-4 步骤。由于这里需要的是异常判定，只需要判断tail_avg是否outlier即可")])])])])]),a._v(" "),_("li",[_("p",[a._v("针对多变量数据")]),a._v(" "),_("ul",[_("li",[a._v("马氏距离")])])])]),a._v(" "),_("h3",{attrs:{id:"基于相似度量的算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于相似度量的算法"}},[a._v("#")]),a._v(" 基于相似度量的算法")]),a._v(" "),_("ol",[_("li",[a._v("KNN\nKNN算法的核心思想是，如果一个样本在特征空间中的K个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。")])]),a._v(" "),_("p",[a._v("算法步骤：\n①准备数据，对数据进行预处理\n②计算测试样本点（也就是待分类点）到其他每个样本点的距离\n③对每个距离进行排序，然后选择出距离最小的K个点\n④对K个点所属的类别进行比较，根据少数服从多数的原则，将测试样本点归入在K个点中占比最高的那一类")]),a._v(" "),_("ol",{attrs:{start:"2"}},[_("li",[_("p",[a._v("基于密度度量")]),a._v(" "),_("ul",[_("li",[a._v("LOF(Local Outlier Factor，局部离群因子检测方法)\nk距离：对于点p，将其他点与之距离进行从小到大排序，第k个即为k距离\nk距离邻域：到点p的距离小于等于k距离点，共k个\n可达距离：若到点p的实际距离小于k距离，则为k距离，反之为实际距离\n局部可达密度：邻域内点到p点可达距离平均值的倒数。\n局部离群因子：领域内点的局部可达密度的均值除以p点的局部可达密度")])]),a._v(" "),_("p",[a._v("局部离群因子(LOF)的大小代表该点为离群点的可信度，即因子越                 大，该点越可能是离群点。\n"),_("img",{attrs:{src:"/blog/img/lof.png",alt:"lof"}})]),a._v(" "),_("ul",[_("li",[a._v("KDE 核密度估计")])])]),a._v(" "),_("li",[_("p",[a._v("基于聚类：K-means，GMM\nK-means算法步骤：")]),a._v(" "),_("ul",[_("li",[a._v("选择初始化的 k 个样本作为初始聚类中心")]),a._v(" "),_("li",[a._v("针对数据集中每个样本计算它到 k 个聚类中心的距离并将其分到距离最小的聚类中心所对应的类中")]),a._v(" "),_("li",[a._v("针对每个类别，重新计算它的聚类中心即属于该类的所有样本的质心")]),a._v(" "),_("li",[a._v("重复上面 2 3 两步操作，直到达到某个中止条件")])])]),a._v(" "),_("li",[_("p",[a._v("基于树：孤立森林(Isolation Forest)\n(1).随机选择一个特征，再在该特征下最大与最小值间随机选择一个值作为切分点，递归切分数据集，直到每个样本点被隔开，从而构建一颗类似CART分类树的随机树。重复构建多颗随机树。\n(2).从根节点到叶节点的路径越长，代表该点越难被隔离，即该点越不可能是异常点。计算每个样本点路径长的平均值，即得到该点得分，得分越低越可能是异常点。\n"),_("img",{attrs:{src:"/blog/img/isolation_forest.png",alt:"孤立森林"}})])]),a._v(" "),_("li",[_("p",[a._v("基于谱(线性模型)：通过与正常谱型进行残差对比，发现异常")]),a._v(" "),_("ul",[_("li",[a._v("One-class SVM(一类支持向量机) 矩阵分解法")]),a._v(" "),_("li",[a._v("Replicator Neural Networks(RNNs)\n神经网络模拟的是一个恒等映射，输入层的神经元个数和输出层的神            经元个数是一样的。")]),a._v(" "),_("li",[a._v("Autoencoders(AE)")])])])]),a._v(" "),_("h2",{attrs:{id:"深度学习方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#深度学习方法"}},[a._v("#")]),a._v(" 深度学习方法")]),a._v(" "),_("h3",{attrs:{id:"介绍-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#介绍-2"}},[a._v("#")]),a._v(" 介绍")]),a._v(" "),_("ol",[_("li",[_("p",[a._v("针对正常数据进行训练建模，然后通过高重构误差来识别异常点，即生成式(Generative)的算法，往往是无监督的，如自编码器(Auto Encoder)类 或者回声状态网络(Echo State Networks)。")])]),a._v(" "),_("li",[_("p",[a._v("对数据的概率分布进行建模，然后根据样本点与极低概率的关联性来识别异常点，如DAGMM。")])]),a._v(" "),_("li",[_("p",[a._v("通过标注数据，告诉模型正常数据点长什么样，异常数据点长什么样，然后通过有监督算法训练分类模型，也称判别式(Discriminative)算法。")])])]),a._v(" "),_("h3",{attrs:{id:"几种深度学习方法-代码实例"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#几种深度学习方法-代码实例"}},[a._v("#")]),a._v(" 几种深度学习方法 + 代码实例")]),a._v(" "),_("ol",[_("li",[_("p",[a._v("基于AutoEncoder的无监督异常检测算法(Tensorflow)")])]),a._v(" "),_("li",[_("p",[a._v("Deep SVDD")])]),a._v(" "),_("li",[_("p",[a._v("基于Transformer掩码重建的时序数据异常检测算法(pyTorch)")])])])])}),[],!1,null,null,null);v.default=r.exports}}]);